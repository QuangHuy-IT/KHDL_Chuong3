{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "019db79a",
   "metadata": {},
   "source": [
    "\n",
    "# BĐS Đà Nẵng → CSV \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f0959d",
   "metadata": {},
   "source": [
    "## 0) Cài thư viện\n",
    "Cài xong thư viện thì nhấn restart rồi từ lần sau không cần chạy cell này nữa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb017cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U pip setuptools wheel\n",
    "%pip install undetected-chromedriver selenium beautifulsoup4 lxml pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec20524",
   "metadata": {},
   "source": [
    "## 1) Cấu hình\n",
    "- BASE_URLS muốn lấy thêm nhiều chỗ khác thì sửa hoặc thêm chỗ này\n",
    "- START_PAGE: Bắt đầu từ trang nào\n",
    "- N_PAGES: muốn nó lấy bao nhiêu trang \n",
    "> Còn lại không phải chỉnh gì"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f06e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, time, random\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Optional\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "BASE_URLS = {\n",
    "    \"Tổng hợp Đà Nẵng\": \"https://batdongsan.com.vn/nha-dat-ban-da-nang\",\n",
    "    \"Bán căn hộ chung cư\": \"https://batdongsan.com.vn/ban-can-ho-chung-cu-da-nang\",\n",
    "    \"Bán nhà riêng\": \"https://batdongsan.com.vn/ban-nha-rieng-da-nang\",\n",
    "    \"Bán nhà mặt phố\": \"https://batdongsan.com.vn/ban-nha-mat-pho-da-nang\",\n",
    "    \"Bán đất\": \"https://batdongsan.com.vn/ban-dat-da-nang\",\n",
    "    \n",
    "}\n",
    "BASE_URL   = BASE_URLS[\"Bán nhà riêng\"]\n",
    "START_PAGE = 2\n",
    "N_PAGES    = 1\n",
    "OUTPUT_CSV = \"bds.csv\"\n",
    "APPEND_MODE = True\n",
    "DELAY_RANGE = (1.5, 2.5)\n",
    "HEADLESS = False  # khuyến nghị để giảm chặn; bật True nếu cần chạy nền\n",
    "VERBOSE_DETAIL = False  # tắt/mở log chi tiết\n",
    "\n",
    "COLS9 = [\"ngay_dang\",\"loai_hinh\",\"dien_tich\",\"gia\",\"giay_to_phap_ly\",\"so_phong_ngu\",\"so_phong_ve_sinh\",\"tinh_trang_noi_that\",\"link\"]\n",
    "\n",
    "def text_clean(x: Optional[str]) -> str:\n",
    "    return re.sub(r\"\\s+\", \" \", x or \"\").strip()\n",
    "\n",
    "def pause(a: Optional[float] = None, b: Optional[float] = None) -> None:\n",
    "    \"\"\"Ngủ ngẫu nhiên trong khoảng [a,b]; nếu không truyền thì dùng DELAY_RANGE.\"\"\"\n",
    "    if a is None or b is None:\n",
    "        a, b = DELAY_RANGE\n",
    "    time.sleep(random.uniform(a, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c51373a",
   "metadata": {},
   "source": [
    "## 2) Lấy link ở danh sách (Selenium headful)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5573137a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def parse_list_page(html: str):\n",
    "    soup = BeautifulSoup(html, \"lxml\")\n",
    "    cards = soup.select(\"div.re__card, div.property-item, div.js__card\")\n",
    "    out = []\n",
    "    if cards:\n",
    "        for c in cards:\n",
    "            a = c.select_one(\"a[href*='/ban-'], a[href*='/nha-dat-'], a[href*='/can-ho-'], a[href*='/dat-']\")\n",
    "            if not a:\n",
    "                continue\n",
    "            href = a.get(\"href\",\"\")\n",
    "            link = href if href.startswith(\"http\") else (\"https://batdongsan.com.vn\"+href)\n",
    "            out.append({\"link\": link})\n",
    "        return out\n",
    "    # Fallback: đi thẳng theo anchor nếu không bắt được card\n",
    "    for a in soup.select(\"a[href*='/ban-'], a[href*='/nha-dat-'], a[href*='/can-ho-'], a[href*='/dat-']\"):\n",
    "        href = a.get(\"href\",\"\")\n",
    "        if not href:\n",
    "            continue\n",
    "        link = href if href.startswith(\"http\") else (\"https://batdongsan.com.vn\"+href)\n",
    "        out.append({\"link\": link})\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41dd0c2e",
   "metadata": {},
   "source": [
    "## 3) Selenium điều hướng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c674223",
   "metadata": {},
   "outputs": [],
   "source": [
    "def human_sleep(a=1.6, b=3.2):\n",
    "    pause(a, b)\n",
    "\n",
    "def human_scroll(driver, steps=8, bottom_pause=(0.8, 1.6)):\n",
    "    h = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    y = 0\n",
    "    for _ in range(steps):\n",
    "        y += max(120, h // steps)\n",
    "        driver.execute_script(f\"window.scrollTo(0, {int(y)});\")\n",
    "        pause(0.4, 0.9)\n",
    "    pause(*bottom_pause)\n",
    "\n",
    "def click_consent_if_any(driver):\n",
    "    texts = [\"Đồng ý\",\"Chấp nhận\",\"Cho phép\",\"Tôi hiểu\",\"Accept\",\"OK\",\"Got it\"]\n",
    "    try:\n",
    "        for b in driver.find_elements(\"css selector\", \"button, .btn, [role='button']\"):\n",
    "            t = (b.text or \"\").strip()\n",
    "            if any(x.lower() in t.lower() for x in texts):\n",
    "                try:\n",
    "                    b.click()\n",
    "                    pause(0.7, 1.0)\n",
    "                    break\n",
    "                except:\n",
    "                    pass\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "def wait_for_cards(driver, timeout=25):\n",
    "    t0 = time.time()\n",
    "    while time.time() - t0 < timeout:\n",
    "        n_cards = driver.execute_script(\"return document.querySelectorAll('div.re__card, div.property-item, div.js__card').length;\")\n",
    "        n_anchors = driver.execute_script(\"return document.querySelectorAll(\\\"a[href*='/ban-'], a[href*='/nha-dat-'], a[href*='/can-ho-'], a[href*='/dat-']\\\").length;\")\n",
    "        if (n_cards and n_cards > 0) or (n_anchors and n_anchors > 0):\n",
    "            return True\n",
    "        pause(0.9, 1.2)\n",
    "    return False\n",
    "\n",
    "def goto_page(driver, base_url: str, page_index: int):\n",
    "    url = base_url if page_index <= 1 else f\"{base_url}/p{page_index}\"\n",
    "    driver.get(url)\n",
    "\n",
    "def click_next_page(driver, current_page_idx: int, base_url: str):\n",
    "    tried = False\n",
    "    try:\n",
    "        for a in driver.find_elements(\"css selector\", \"a[rel='next'], a[aria-label*='Sau'], a[title*='Sau'], li a\"):\n",
    "            t = (a.get_attribute(\"aria-label\") or \"\") + \" \" + (a.get_attribute(\"title\") or \"\") + \" \" + (a.text or \"\")\n",
    "            if any(x in t.lower() for x in [\"sau\",\"next\",\"tiếp\",\">\",\"»\"]):\n",
    "                a.click(); tried = True; break\n",
    "    except: pass\n",
    "    if not tried:\n",
    "        goto_page(driver, base_url, current_page_idx + 1)\n",
    "\n",
    "def crawl_list_links(n_pages: int, base_url: str, start_page: int):\n",
    "    import undetected_chromedriver as uc\n",
    "    from selenium.webdriver.chrome.options import Options\n",
    "    opts = Options()\n",
    "    if HEADLESS:\n",
    "        opts.add_argument(\"--headless=new\")\n",
    "    opts.add_argument(\"--disable-gpu\"); opts.add_argument(\"--no-sandbox\"); opts.add_argument(\"--disable-dev-shm-usage\")\n",
    "    opts.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "    opts.add_argument(\"--window-size=1366,768\"); opts.add_argument(\"--lang=vi-VN\")\n",
    "    # User-Agent phổ biến để giảm chặn\n",
    "    opts.add_argument(\"--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\")\n",
    "    driver = uc.Chrome(options=opts)\n",
    "    results = []\n",
    "    try:\n",
    "        goto_page(driver, base_url, start_page)\n",
    "        pause()\n",
    "        click_consent_if_any(driver)\n",
    "        human_scroll(driver, steps=10)\n",
    "        wait_for_cards(driver, timeout=25)\n",
    "        current_idx = start_page\n",
    "        for i in range(n_pages):\n",
    "            # Thử tối đa 2 lần nếu trang hiện tại chưa bắt được link\n",
    "            attempts = 2\n",
    "            page_items = []\n",
    "            for _ in range(attempts):\n",
    "                html = driver.page_source\n",
    "                page_items = parse_list_page(html)\n",
    "                if page_items:\n",
    "                    break\n",
    "                # scroll sâu thêm rồi đợi\n",
    "                human_scroll(driver, steps=12)\n",
    "                pause(1.0, 1.6)\n",
    "                wait_for_cards(driver, timeout=10)\n",
    "            seen = set(x[\"link\"] for x in results)\n",
    "            for it in page_items:\n",
    "                if it[\"link\"] not in seen:\n",
    "                    results.append(it); seen.add(it[\"link\"])\n",
    "            print(f\"[List Page {current_idx}] links (raw): {len(page_items)} | unique_total: {len(results)}\")\n",
    "            if len(page_items) == 0:\n",
    "                print(\"[Hint] 0 link: trang có thể bị chặn/che overlay. Hãy thử HEADLESS=False (đã để mặc định) hoặc tăng DELAY_RANGE.\")\n",
    "            # Nếu còn trang phải xử lý thì mới chuyển trang\n",
    "            if i < n_pages - 1:\n",
    "                click_next_page(driver, current_page_idx=current_idx, base_url=base_url)\n",
    "                current_idx += 1\n",
    "                pause()\n",
    "                click_consent_if_any(driver)\n",
    "                human_scroll(driver, steps=8)\n",
    "                wait_for_cards(driver, timeout=20)\n",
    "    finally:\n",
    "        driver.quit()\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71be213a",
   "metadata": {},
   "source": [
    "## 4) Regex-first trên section “Đặc điểm bất động sản”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34e5e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "BAD_VALUES = {\"tai ung dung\",\"tải ứng dụng\",\"xem thêm trên app\",\"app\",\"ứng dụng\"}\n",
    "\n",
    "def get_breadcrumb_type(soup: BeautifulSoup) -> str:\n",
    "    for sel in [\"nav[aria-label*='breadcrumb'] a\", \".re__breadcrumb a\", \"ol.breadcrumb a\"]:\n",
    "        links = [text_clean(a.get_text()) for a in soup.select(sel) if text_clean(a.get_text())]\n",
    "        if links:\n",
    "            for txt in reversed(links):\n",
    "                if \"căn hộ\" in txt.lower(): return txt\n",
    "            return links[-1]\n",
    "    a = soup.select_one(\"a.re__link-se\")\n",
    "    if a:\n",
    "        txt = text_clean(a.get_text())\n",
    "        if \"căn hộ\" in txt.lower(): return txt\n",
    "    a2 = soup.select_one(\"nav a:last-child, ol.breadcrumb li:last-child a\")\n",
    "    return text_clean(a2.get_text()) if a2 else \"\"\n",
    "\n",
    "def get_characteristics_text(soup: BeautifulSoup) -> str:\n",
    "    # tìm section có 'Đặc điểm bất động sản', nếu không thấy dùng toàn trang\n",
    "    for sec in soup.select(\"section, .re__section, .re__pr-specs\"):\n",
    "        head = sec.find([\"h2\",\"h3\",\"h4\"])\n",
    "        if head and \"đặc điểm\" in text_clean(head.get_text()).lower():\n",
    "            return sec.get_text(\"\\n\", strip=True)\n",
    "    return soup.get_text(\"\\n\", strip=True)\n",
    "\n",
    "def rex_search(patterns, text, flags=re.I):\n",
    "    if isinstance(patterns, str): patterns = [patterns]\n",
    "    for p in patterns:\n",
    "        m = re.search(p, text, flags)\n",
    "        if m: return m\n",
    "    return None\n",
    "\n",
    "def extract_fields_from_text(txt: str) -> dict:\n",
    "    # Chuẩn hóa khoảng trắng nhưng GIỮ xuống dòng để bắt đầu dòng bằng nhãn\n",
    "    t = re.sub(r\"[ \\t]+\", \" \", txt)\n",
    "\n",
    "    def find_line_value(label_pattern: str) -> str:\n",
    "        m = re.search(rf\"^(?:{label_pattern})\\s*[:\\-]?\\s*([^\\n\\r]+)\", t, flags=re.I | re.M)\n",
    "        return text_clean(m.group(1)) if m else \"\"\n",
    "\n",
    "    # Giá (ưu tiên nhãn chính xác ở đầu dòng)\n",
    "    gia = find_line_value(r\"Khoảng\\s*giá|Mức\\s*giá|Giá\")\n",
    "\n",
    "    # Diện tích (dạng '70 m²' giữ nguyên số thập phân dùng dấu phẩy)\n",
    "    m = re.search(r\"^Diện\\s*tích\\s*[:\\-]?\\s*([0-9\\.,]+ ?m²)\", t, flags=re.I | re.M)\n",
    "    dien_tich = text_clean(m.group(1)) if m else \"\"\n",
    "\n",
    "    # Phòng ngủ\n",
    "    pn_raw = find_line_value(r\"Số\\s*phòng\\s*ngủ\")\n",
    "\n",
    "    # WC\n",
    "    m_wc = re.search(r\"^Số\\s*phòng\\s*tắm,\\s*vệ\\s*sinh\\s*[:\\-]?\\s*([0-9]+)\", t, flags=re.I | re.M)\n",
    "    wc_raw = m_wc.group(1) if m_wc else find_line_value(r\"(?:WC|Vệ\\s*sinh|Toilet|Phòng\\s*tắm)\")\n",
    "\n",
    "    # Nội thất\n",
    "    noi_that_raw = find_line_value(r\"Nội\\s*thất\")\n",
    "    noi_that = \"\"\n",
    "    if noi_that_raw:\n",
    "        m2 = re.search(r\"(đầy\\s*đủ|full\\s*nội\\s*thất|cơ\\s*bản|trống|không\\s*nội\\s*thất)\", noi_that_raw, flags=re.I)\n",
    "        noi_that = text_clean(m2.group(0)) if m2 else noi_that_raw\n",
    "\n",
    "    # Pháp lý\n",
    "    giay_to = find_line_value(r\"(?:Pháp\\s*lý|Giấy\\s*tờ(?:\\s*pháp\\s*lý)?)\")\n",
    "    if any(bad in giay_to.lower() for bad in BAD_VALUES):\n",
    "        giay_to = \"\"\n",
    "\n",
    "    # Làm sạch 'phòng' khỏi số lượng\n",
    "    def only_digits(s: str) -> str:\n",
    "        m = re.search(r\"\\d+\", s or \"\")\n",
    "        return m.group(0) if m else (s or \"\").strip()\n",
    "\n",
    "    so_pn = only_digits(pn_raw)\n",
    "    so_wc = only_digits(wc_raw)\n",
    "\n",
    "    # Loại bỏ giá trị giá không hợp lệ (ví dụ 'Biểu đồ giá')\n",
    "    if gia and any(x in gia.lower() for x in {\"biểu đồ giá\", \"liên hệ\", \"đang cập nhật\"}):\n",
    "        gia = \"\"\n",
    "\n",
    "    return {\n",
    "        \"gia\": gia,\n",
    "        \"dien_tich\": dien_tich,\n",
    "        \"so_phong_ngu\": so_pn,\n",
    "        \"so_phong_ve_sinh\": so_wc,\n",
    "        \"tinh_trang_noi_that\": noi_that,\n",
    "        \"giay_to_phap_ly\": giay_to,\n",
    "    }\n",
    "\n",
    "def extract_ngay_dang(soup: BeautifulSoup) -> str:\n",
    "    for node in soup.select(\"section, .re__pr-time, .re__pr-config, .re__pr-attribute, [class*='time'], [class*='date']\"):\n",
    "        txt = text_clean(node.get_text(\" \", strip=True))\n",
    "        if \"ngày đăng\" in txt.lower():\n",
    "            m = re.search(r\"(\\d{1,2}/\\d{1,2}/\\d{4})\", txt)\n",
    "            if m: return m.group(1)\n",
    "    m = re.search(r\"(\\d{1,2}/\\d{1,2}/\\d{4})\", soup.get_text(\" \", strip=True))\n",
    "    return m.group(1) if m else \"\"\n",
    "\n",
    "def extract_detail_v8(html: str, link: str) -> Dict[str, str]:\n",
    "    soup = BeautifulSoup(html, \"lxml\")\n",
    "    sec_text = get_characteristics_text(soup)\n",
    "    fields = extract_fields_from_text(sec_text)\n",
    "    return {\n",
    "        \"ngay_dang\": extract_ngay_dang(soup),\n",
    "        \"loai_hinh\": get_breadcrumb_type(soup),\n",
    "        \"dien_tich\": fields[\"dien_tich\"],\n",
    "        \"gia\": fields[\"gia\"],\n",
    "        \"giay_to_phap_ly\": fields[\"giay_to_phap_ly\"],\n",
    "        \"so_phong_ngu\": fields[\"so_phong_ngu\"],\n",
    "        \"so_phong_ve_sinh\": fields[\"so_phong_ve_sinh\"],\n",
    "        \"tinh_trang_noi_that\": fields[\"tinh_trang_noi_that\"],\n",
    "        \"link\": link,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96aae2c3",
   "metadata": {},
   "source": [
    "## 5) Crawl → chi tiết → 9 cột"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef8a67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl_v8(n_pages: int, base_url: str, start_page: int) -> pd.DataFrame:\n",
    "    links = crawl_list_links(n_pages, base_url, start_page)\n",
    "    if not links: return pd.DataFrame(columns=COLS9)\n",
    "\n",
    "    if VERBOSE_DETAIL:\n",
    "        print(f\"[Detail] Tổng link sẽ crawl: {len(links)}\")\n",
    "\n",
    "    import undetected_chromedriver as uc\n",
    "    from selenium.webdriver.chrome.options import Options\n",
    "    opts = Options()\n",
    "    if HEADLESS:\n",
    "        opts.add_argument(\"--headless=new\")\n",
    "    opts.add_argument(\"--disable-gpu\"); opts.add_argument(\"--no-sandbox\"); opts.add_argument(\"--disable-dev-shm-usage\")\n",
    "    opts.add_argument(\"--window-size=1366,768\"); opts.add_argument(\"--lang=vi-VN\")\n",
    "    driver = uc.Chrome(options=opts)\n",
    "\n",
    "    rows = []\n",
    "    try:\n",
    "        total = len(links)\n",
    "        for idx, it in enumerate(links, start=1):\n",
    "            url = it[\"link\"]\n",
    "            success = False\n",
    "            for attempt in range(1, 3):  # 2 attempts\n",
    "                try:\n",
    "                    driver.get(url)\n",
    "                    pause(1.8, 2.8)\n",
    "                    html = driver.page_source\n",
    "                    rows.append(extract_detail_v8(html, link=url))\n",
    "                    if VERBOSE_DETAIL:\n",
    "                        print(f\"[Detail {idx}/{total}] OK\")\n",
    "                    pause(0.8, 1.4)\n",
    "                    success = True\n",
    "                    break\n",
    "                except Exception as e:\n",
    "                    if VERBOSE_DETAIL:\n",
    "                        print(f\"[Detail {idx}/{total}] Retry {attempt} error: {e}\")\n",
    "                    pause(1.2, 2.0)\n",
    "            if not success:\n",
    "                miss = {k:\"\" for k in COLS9}; miss[\"link\"] = url; rows.append(miss)\n",
    "                if VERBOSE_DETAIL:\n",
    "                    print(f\"[Detail {idx}/{total}] FAIL -> added empty row\")\n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "    return pd.DataFrame(rows, columns=COLS9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d656f9a4",
   "metadata": {},
   "source": [
    "## 6) Append theo link (ưu tiên dữ liệu mới không rỗng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016109f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def smart_append_by_link(old_df: pd.DataFrame, new_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    for c in COLS9:\n",
    "        if c not in old_df.columns: old_df[c] = \"\"\n",
    "        if c not in new_df.columns: new_df[c] = \"\"\n",
    "    old_df = old_df[COLS9].drop_duplicates(subset=[\"link\"], keep=\"first\")\n",
    "    new_df = new_df[COLS9].drop_duplicates(subset=[\"link\"], keep=\"first\")\n",
    "    both = pd.concat([old_df, new_df], ignore_index=True).sort_values(\"link\")\n",
    "\n",
    "    def pick_nonempty(series):\n",
    "        for v in series[::-1]:\n",
    "            if pd.notna(v) and str(v).strip() != \"\":\n",
    "                return v\n",
    "        return series.iloc[-1]\n",
    "\n",
    "    merged = both.groupby(\"link\", as_index=False).agg({c: pick_nonempty for c in COLS9})\n",
    "    return merged[COLS9]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960fb911",
   "metadata": {},
   "source": [
    "## 7) RUN ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2e1a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"BASE_URL:\", BASE_URL, \"| START_PAGE:\", START_PAGE, \"| N_PAGES:\", N_PAGES)\n",
    "df_new = crawl_v8(N_PAGES, BASE_URL, START_PAGE)\n",
    "print(\"Số dòng mới:\", len(df_new))\n",
    "\n",
    "csv_path = Path(OUTPUT_CSV)\n",
    "if APPEND_MODE and csv_path.exists():\n",
    "    old_df = pd.read_csv(csv_path)\n",
    "    final_df = smart_append_by_link(old_df, df_new)\n",
    "else:\n",
    "    final_df = df_new\n",
    "\n",
    "final_df.to_csv(csv_path, index=False, encoding=\"utf-8-sig\")\n",
    "print(f\"✅ Đã lưu CSV: {OUTPUT_CSV} (tổng {len(final_df)} dòng)\")\n",
    "display(final_df.head(20))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
